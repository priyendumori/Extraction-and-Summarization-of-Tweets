{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import add\n",
    "from scipy import spatial\n",
    "import glob\n",
    "import sys\n",
    "import numpy\n",
    "from scipy.spatial import distance\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random \n",
    "import heapq\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model= Doc2Vec.load(\"d2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentences(tag):\n",
    "    files = glob.glob(\"Extraction-and-Summarization-of-Tweets/data/tweets/\"+tag+\"/*\")\n",
    "    sentences = []\n",
    "    for file in files:\n",
    "        fd = open(file,\"r\")\n",
    "        for line in fd:\n",
    "            sentences.append(line)\n",
    "    return sentences\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vectors(sentences):\n",
    "    sen_vectors = []\n",
    "    for sentence in sentences:\n",
    "        test_data = word_tokenize(sentence.lower())\n",
    "        v1 = model.infer_vector(test_data)\n",
    "        sen_vectors.append(v1)\n",
    "    return sen_vectors\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ranking(sentence_vectors,sentences):\n",
    "    centroid_vector = [0 for i in range(len(sentence_vectors[0]))]\n",
    "    l = len(sentences)\n",
    "    for vector in sentence_vectors:\n",
    "        centroid_vector = list(map(add, centroid_vector, vector))\n",
    "    rank = []\n",
    "    count = 0\n",
    "    for vector in sentence_vectors:\n",
    "        rank.append([cosine_similarity([vector,centroid_vector])[0][1],sentences[count]])\n",
    "        count+=1\n",
    "    return rank , list(numpy.array(centroid_vector)/l) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def beam_search(candidate_set,vectors,theta,k,dm_avg):\n",
    "    l = len(candidate_set)\n",
    "    lk = []\n",
    "    lold = []\n",
    "    lnew = []\n",
    "    for j in range(k): \n",
    "        lold.append([candidate_set[random.randint(0, l)][1]])\n",
    "    #print(lold)\n",
    "    while len(lold):\n",
    "        for sentence in candidate_set:\n",
    "            for summary_set in lold:\n",
    "                if sentence[1] not in summary_set:\n",
    "                    summary_set = summary_set + [sentence[1]]\n",
    "                    test_data = word_tokenize('.'.join(summary_set).lower())\n",
    "                    v1 = model.infer_vector(test_data)\n",
    "                    error = (distance.euclidean(v1, dm_avg))**2 \n",
    "                    if len(summary_set) < theta:\n",
    "                        lnew.append([error,summary_set])\n",
    "                        lnew = heapq.nsmallest(k,lnew)\n",
    "                    elif len(summary_set) == theta:\n",
    "                        lk.append([error,summary_set])\n",
    "                        lk = heapq.nsmallest(k,lk)\n",
    "        \n",
    "        lold = [row[1] for row in lnew]\n",
    "        lnew = []\n",
    "    \n",
    "    return '.'.join(lk[0][1])\n",
    "                        \n",
    "                        \n",
    "                \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hashtag = sys.argv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = get_sentences(\"metoo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sen_vectors = get_vectors(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candidate_set,dm_avg = ranking(sen_vectors,sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "summary = beam_search(candidate_set,sen_vectors,5,5,dm_avg) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Be careful,\" other women whispered to me when they found out I was working on projects with Rev.@BudHeckman. Now, 4 amazingly strong and brave women are bringing his behavior to and they must hold him accountable. .It\\'s false accusations like this that hurt Ali could just as well be victim here as was Johnny Depp etc. Learn to hear both sides of the story for the movement to succeed. .If HR is such a vital component of American business, asks how did it miss the kind of sexual harassment at the center of the movement? .Suddenly, our body\\'s in fight, flight, or freeze. With our heart racing, we face frightful memories. I\\'ve learned we cannot outrun trauma. Despite how many years I\\'ve tried to escape the mental torment, I realized the only way to heal is to feel the pain. .The cost of speaking up. How many deaths have taken place in Pakistan and elsewhere? When women stand up to sexual harassment and are slapped with defamation suits, penalties and intimidation. '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
